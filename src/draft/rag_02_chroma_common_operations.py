
import sys 
import os
import torch
from pathlib import Path
from dotenv import load_dotenv
import chromadb 

load_dotenv()

__file__ = '/Users/hzz/KMS/IC-RAG-Agent/src/draft/load_split_pdf.py'
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / 'libs/ai-toolkit/'))


# é…ç½®Chromaå­˜å‚¨å‚æ•°
CHROMA_PERSIST_PATH = str(project_root / "data/chroma_db/amazon/fba")  # æŒ‰ä¸šåŠ¡ç»´åº¦åˆ’åˆ†è·¯å¾„
COLLECTION_NAME = "amazon_fba_features" 

# åˆå§‹åŒ–Qwen3-VL-Embedding-2Bæ¨¡å‹
from typing import List
from langchain_core.embeddings import Embeddings

# Add model scripts to path
model_scripts_path = project_root / "models/Qwen3-VL-Embedding-2B/scripts"
if model_scripts_path.is_dir():
    sys.path.insert(0, str(model_scripts_path))

def _patch_torch_autocast_for_older_pytorch() -> None:
    """Patch torch.is_autocast_enabled for older PyTorch versions"""
    if getattr(torch.is_autocast_enabled, "_qwen_patched", False):
        return
    try:
        torch.is_autocast_enabled("cpu")
    except TypeError:
        original = torch.is_autocast_enabled
        def _patched(device_type=None):
            return original()
        _patched._qwen_patched = True
        torch.is_autocast_enabled = _patched

_patch_torch_autocast_for_older_pytorch()

from qwen3_vl_embedding import Qwen3VLEmbedder

class LocalQwenEmbeddings(Embeddings):
    """LangChain Embeddings wrapper for local Qwen3-VL-Embedding-2B"""
    def __init__(self, model_path: str, max_length: int = 8192):
        self.embedder = Qwen3VLEmbedder(
            model_name_or_path=model_path,
            max_length=max_length,
        )
        print(f"âœ… å·²åŠ è½½ Qwen3-VL-Embedding-2B æ¨¡å‹")
    
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        if not texts:
            return []
        inputs = [{"text": t} for t in texts]
        out = self.embedder.process(inputs, normalize=True)
        out = out.to(dtype=torch.float32)
        arr = out.cpu().numpy()
        if arr.ndim == 1:
            return [arr.tolist()]
        return [arr[i].tolist() for i in range(len(arr))]
    
    def embed_query(self, text: str) -> List[float]:
        inputs = [{"text": text}]
        out = self.embedder.process(inputs, normalize=True)
        out = out.to(dtype=torch.float32)
        arr = out.cpu().numpy()
        if arr.ndim == 2:
            return arr[0].tolist()
        return arr.tolist()

    def name(self):
        return "Qwen3-VL-Embedding-2B"


model_path = str(project_root / "models/Qwen3-VL-Embedding-2B")
embeddings = LocalQwenEmbeddings(model_path)


# 1. åˆå§‹åŒ–å®¢æˆ·ç«¯
# åˆå§‹åŒ–ChromaæŒä¹…åŒ–å®¢æˆ·ç«¯ï¼ˆæ•°æ®è½åœ°åˆ°æŒ‡å®šè·¯å¾„ï¼‰
chroma_client = chromadb.PersistentClient(path=CHROMA_PERSIST_PATH)

# 2. è·å–/åˆ›å»ºé›†åˆ
# è‹¥ä¸æŒ‡å®š embedding_function, åˆ™é»˜è®¤ä½¿ç”¨Chromaçš„é»˜è®¤embeddingæ¨¡å‹ï¼Œè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨Qwen3-VL-Embedding-2Bæ¨¡å‹
collection = chroma_client.get_or_create_collection(name=COLLECTION_NAME)
# collection = chroma_client.get_or_create_collection(name=COLLECTION_NAME, embedding_function=embeddings)


# 3.ç»Ÿè®¡æ•°æ®é‡, æˆ–æµ‹è¯•é›†åˆæ˜¯å¦å­˜åœ¨
collection.count()

# 4.æŸ¥è¯¢ collection å†…å®¹
# 4.1 è¿”å›æ‰€æœ‰ids 
# include=["ids", "metadatas", "documents", "embeddings"]ï¼šè¿”å›æ‰€æœ‰å­—æ®µï¼ˆæŒ‰éœ€é€‰æ‹©ï¼Œé¿å…åŠ è½½ä¸å¿…è¦çš„å‘é‡æ•°æ®ï¼‰ï¼›
ids = collection.get(include=[])["ids"]  # include=[] è¡¨ç¤ºåªè·å–idsï¼Œä¸åŠ è½½å…¶ä»–æ•°æ®
print(ids)

# 4.2 ç®€å•è·å–å‰ N æ¡æ•°æ®ï¼ˆé»˜è®¤æŒ‰æ’å…¥é¡ºåºï¼‰
all_items_preview = collection.get(
    limit=5,  # only fetch first 5 items for preview
    include=["metadatas", "documents"]
)
print("ğŸ” Preview first 5 items in collection:")
print(all_items_preview)

# 4.3 æŒ‰ ID ç²¾ç¡®è·å–æŒ‡å®šæ¡ç›®
sample_ids = ids[:2] if len(ids) >= 2 else ids  # reuse ids we just inserted if available
if sample_ids:
    items_by_id = collection.get(
        ids=sample_ids,
        include=["documents", "metadatas"]
    )
    print(f"ğŸ” Fetch items by ids={sample_ids}:")
    print(items_by_id)

# 4.3 æŒ‰å…ƒæ•°æ®è¿‡æ»¤ï¼ˆä¾‹å¦‚ï¼šæŒ‰ source æ–‡ä»¶è·¯å¾„è¿‡æ»¤ï¼‰
"""
{'page_label': '1',
   'source': '/Users/hzz/KMS/IC-RAG-Agent/data/documents/sales_platform/amazon/fba/FBA features/FBA Global Selling.pdf',
   'creationdate': '2026-02-02T13:37:42+00:00',
   'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/144.0.0.0 Safari/537.36',
   'total_pages': 3,
   'title': 'Amazon',
   'start_index': 0,
   'moddate': '2026-02-02T13:37:42+00:00',
   'page': 0,
   'producer': 'Skia/PDF m144'}
"""

items_by_metadata = collection.get(
    where={"page": 0},  # metadata key 'source' is added by loader
    limit=3,
    include=["metadatas", "documents"]
)
print(f"ğŸ” Fetch items where page == '0':")
print(items_by_metadata)

# 4.4 æŒ‰æ–‡æ¡£å†…å®¹è¿‡æ»¤ï¼ˆä¾‹å¦‚ï¼šåŒ…å«æŸä¸ªå…³é”®è¯ï¼‰
items_by_document = collection.get(
    where_document={"$contains": "customer service"},
    limit=3,
    include=["metadatas", "documents"]
)
print("ğŸ” Fetch items where document contains 'customer service':")
print(items_by_document)

# 4.5 ä½¿ç”¨ limit / offset åšç®€å•åˆ†é¡µ
page_size = 5
page_2_items = collection.get(
    limit=page_size,
    offset=page_size,  # skip first page_size items
    include=["ids", "metadatas"]
)
print(f"ğŸ” Fetch page 2 items (limit={page_size}, offset={page_size}):")
print(page_2_items)


# 5. æ–°å¢æ•°æ®
# 5.1 åŠ è½½å¹¶å‡†å¤‡æ–‡æ¡£æ•°æ®
from ai_toolkit.rag.loaders import load_pdf_document
from ai_toolkit.rag.splitters import split_document_recursive

pdf_path = '/Users/hzz/KMS/IC-RAG-Agent/data/documents/sales_platform/amazon/fba/FBA features/FBA customer service.pdf'
pdf_docs = load_pdf_document(pdf_path)
split_docs = split_document_recursive(pdf_docs)
print(f"ğŸ“„ å·²åŠ è½½å¹¶åˆ†å‰²æ–‡æ¡£ï¼Œå…± {len(split_docs)} ä¸ªåˆ†å—")

# 5.2 æå–æ–‡æ¡£ä¿¡æ¯
current_ids = collection.get(include=[])["ids"]
texts = [doc.page_content for doc in split_docs]
metadatas = [doc.metadata for doc in split_docs]
new_ids = [f"{COLLECTION_NAME}_{i}" for i in range(len(current_ids), len(current_ids) + len(split_docs))]
print(f"ğŸ“ å‡†å¤‡æ–°å¢ {len(texts)} æ¡æ•°æ®åˆ°é›†åˆ '{COLLECTION_NAME}'")

# 5.3 ç”Ÿæˆå‘é‡
print("ğŸ”„ æ­£åœ¨ç”Ÿæˆæ–‡æ¡£å‘é‡...")
vectors = embeddings.embed_documents(texts)
print(f"âœ… å‘é‡ç”Ÿæˆå®Œæˆï¼Œç»´åº¦: {len(vectors[0])}")

# 5.4 æ‰¹é‡å†™å…¥Chroma
collection.add(
    documents=texts,
    metadatas=metadatas,
    ids=new_ids,
    embeddings=vectors
)
print(f"âœ… æˆåŠŸå°† {len(texts)} ä¸ªæ–‡æ¡£åˆ†å—å­˜å…¥ Chroma")
print(f"ğŸ“Š å½“å‰é›†åˆæ€»æ•°æ®é‡: {collection.count()} æ¡")


# 6. è¯­ä¹‰æ£€ç´¢
## 6.1 use words 
words = "what's the FBA customer service"
res1 = collection.query(query_texts=[words], n_results=2)

## 6.2 use vector
query_vector = embeddings.embed_query(words)
res2 = collection.query(
        query_embeddings=[query_vector],
        n_results=3,
        include=["documents", "metadatas", "distances"]
    )


# 7. åˆ é™¤æ•°æ®
collection.delete(ids=["fba_001"])


