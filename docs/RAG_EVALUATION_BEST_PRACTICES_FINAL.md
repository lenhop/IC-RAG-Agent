# IC-RAG-Agent RAG 评估方案（最终版）

整合 prompts 思路、豆包优化方案与 RAG 最佳实践，形成可落地的评估方案。

---

## 1. 数据集构建（50 条）

### 1.1 数据来源与占比

| 来源 | 占比 | 采集规则 |
|------|------|----------|
| Amazon SellerCentral FAQ | 60%（30 条） | 高频、高客诉、易出错问题（如退款、FBA 仓储） |
| Seller Assistant | 20%（10 条） | 典型问答，含边界场景（如多店铺政策） |
| 官方 Documents | 20%（10 条） | 从手册/政策拆解具体问答（税率、物流等） |

### 1.2 数据分层

- **基础场景**（30 条）：单文档、单答案、无歧义
- **复杂场景**（20 条）：多文档拼接、条件判断、易混淆（如不同站点退货政策）

### 1.3 单条数据字段

- `question`：用户问题
- `ground_truth`：标准答案或核心要点
- `contexts`：理想检索文档 chunk（含 chunk ID/位置）

---

## 2. 评估维度

| 层级 | 评估内容 |
|------|----------|
| **检索层** | 是否召回正确文档 |
| **生成层** | 答案是否忠实、相关、完整 |
| **端到端** | 是否满足用户需求 |

---

## 3. 检索层评估

### 3.1 核心指标

| 指标 | 说明 | 目标 |
|------|------|------|
| **Recall@5** | top-5 中相关 chunk 数 / 总相关数 | 越高越好 |
| **Precision@5** | top-5 中相关 chunk 数 / 5 | 越高越好 |
| **MRR** | 首个相关结果的排名倒数 | 越高越好 |

### 3.2 UMAP 可视化

- **步骤**：用 all-MiniLM-L6-v2 提取 query 与 chunk 的 embedding → UMAP 降维至 2D → 绘制散点图
- **配色**：问题（红）、相关 chunk（绿）、无关 chunk（灰）
- **用途**：定性分析检索偏差（如问题与无关 chunk 过近、相关 chunk 分散）
- **注意**：仅选测试集相关 chunk，降低计算量

---

## 4. 生成层评估

### 4.1 LLM-as-Judge（必做）

| 维度 | Prompt 要点 | 评分 |
|------|-------------|------|
| **忠实度** | 答案是否完全基于 context，无编造/夸大 | 是/否，目标「是」≥85% |
| **回答相关性** | 是否完整、准确回答问题 | 1–5 分，目标≥4 |

- 建议用 gpt-4o/minimax 等中端 LLM，保留打分理由便于复盘
- 人工标注 10 条作对照，LLM 与人工偏差≤10% 即可

### 4.2 客观指标（可选）

- **RAGAS**：`context_precision`、`answer_relevancy`
- **有 ground_truth 时**：F1、ROUGE-L

---

## 5. 工具与实现

| 工具 | 用途 |
|------|------|
| **RAGAS** | Faithfulness、Answer Relevancy、Context Precision |
| **UMAP** | 检索可视化 |
| **LLM** | 忠实度、相关性打分 |

---

## 6. 落地节奏

| 阶段 | 周期 | 内容 |
|------|------|------|
| **阶段 1** | 1–2 天 | 20 条核心用例；Recall@5 + UMAP；LLM 忠实度+相关性 |
| **阶段 2** | 3–5 天 | 补足 50 条；Recall@5/Precision@5；RAGAS；UMAP 异常与 LLM 低分对照分析 |
| **阶段 3** | 持续 | 黄金测试集；每次迭代回归评估；针对低分场景调 embedding、top-K、prompt |

---

## 7. 注意事项

1. **Embedding**：统一用 all-MiniLM-L6-v2，与线上一致
2. **UMAP**：定性分析用，不替代量化指标
3. **LLM 打分**：需人工对照验证一致性
4. **结论**：产出可执行结论（如「Recall@5 仅 60%，FBA 仓储类检索失效」），而非只列数字

---

## 8. 输出物

1. 测试集（50 条，含标注）
2. 检索层：Recall@5/Precision@5 统计表 + UMAP 图（标异常点）
3. 生成层：LLM 打分表 + RAGAS 报告
4. 问题清单：按「检索失效 / 生成不忠实 / 回答不相关」分类，附优化建议

---

## 9. 快速参考

| 目标 | 方法 |
|------|------|
| 检索质量 | Recall@5、Precision@5、UMAP |
| 生成质量 | LLM 忠实度+相关性、RAGAS |
| 回归验证 | 黄金测试集 + 自动化指标 |
| 生产监控 | 用户反馈、延迟、错误率 |
